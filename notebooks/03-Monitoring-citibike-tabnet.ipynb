{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citibike ML\n",
    "In this example we use the [Citibike dataset](https://ride.citibikenyc.com/system-data). Citibike is a bicycle sharing system in New York City. Everyday users choose from 20,000 bicycles at 1300 stations around New York City.\n",
    "\n",
    "To ensure customer satisfaction Citibike needs to predict how many bicycles will be needed at each station. Maintenance teams from Citibike will check each station and repair or replace bicycles. Additionally, the team will relocate bicycles between stations based on predicted demand. The business needs to be able to run reports of how many bicycles will be needed at a given station on a given day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML  Monitoring and Evaluation\n",
    "In this section of the demo, we will utilize Snowpark's Python client-side Dataframe API and server-side runtime to build an **ML ops monitoring process**.  We will start from the automated pipeline that has been built for ingest, feature engineering, traing and inference and add evaluation and monitoring steps.\n",
    "\n",
    "The ML Engineer must create a pipeline step to evaluate the ML model performance over time. Because we are retraining with each inference we will evaluate performance for final 30 days of the predictions.  Additionally, since data scientists may use many different model frameworks, we want to have a standard evaluation framework instead of using the model built-in evaluation which will be different for each framework.  We will deploy the evaluation functions to the Snowpark Python server-side runtime as UDF so that all projects will have a **standard, centralized framework for evaluation and monitoring**.  We will save the model performance metrics in tables for historical analysis and drift detection as well as full reproducibility to support the company's GDPR policies.\n",
    "\n",
    "For this demo flow we will assume that the organization has the following **policies and processes** :   \n",
    "-**Dev Tools**: The ML engineer can develop in their tool of choice (ie. VS Code, IntelliJ, Pycharm, Eclipse, etc.).  Snowpark Python makes it possible to use any environment where they have a python kernel.  For the sake of a demo we will use Jupyter.  \n",
    "-**Data Governance**: To preserve customer privacy no data can be stored locally.  The ingest system may store data temporarily but it must be assumed that, in production, the ingest system will not preserve intermediate data products between runs. Snowpark Python allows the user to push-down all operations to Snowflake and bring the code to the data.   \n",
    "-**Automation**: Although the ML engineer can use any IDE or notebooks for development purposes the final product must be python code at the end of the work stream.  Well-documented, modularized code is necessary for good ML operations and to interface with the company's CI/CD and orchestration tools.  \n",
    "-**Compliance**: Any ML models must be traceable back to the original data set used for training.  The business needs to be able to easily remove specific user data from training datasets and retrain models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Predictions in `PRED_<model_id>` table. Unique model ID number.  \n",
    "Output: Evaluation metrics in `EVAL_<model_id>` table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load  credentials and connect to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark as snp\n",
    "from snowflake.snowpark import functions as F \n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import getpass\n",
    "\n",
    "with open('creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    connection_parameters = {\n",
    "      'account': data['account'],\n",
    "      'user': data['username'],\n",
    "      'password': data['password'], #getpass.getpass(),\n",
    "      'role': data['role'],\n",
    "      'warehouse': data['warehouse']}\n",
    "\n",
    "session = snp.Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_db_name = 'CITIBIKEML'\n",
    "project_schema_name = 'DEMO'\n",
    "project_db_schema = str(project_db_name)+'.'+str(project_schema_name)\n",
    "\n",
    "###For testing we will hard code an existing model_id\n",
    "model_id = '56CDBD02_7C61_11EC_B130_ACDE48001122'\n",
    "###\n",
    "\n",
    "\n",
    "pred_table_name = str(project_db_schema)+'.'+'PREDICTIONS_'+str(model_id)\n",
    "\n",
    "eval_table_name = str(project_db_schema)+'.'+'EVAL_'+str(model_id)\n",
    "_ = session.sql('DROP TABLE IF EXISTS '+eval_table_name).collect()\n",
    "\n",
    "_ = session.sql('USE DATABASE ' + str(project_db_name)).collect()\n",
    "_ = session.sql('USE SCHEMA ' + str(project_schema_name)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: \n",
    "We will use [rexmex](https://rexmex.readthedocs.io/en/latest/index.html) for consistent evaluation rather than the models' built-in eval metrics.  Evaluation metrics will be saved as table output tagged with the model_id.  \n",
    "  \n",
    "First we will create a UDF for the evaluation with Rexmex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_output_func(input_data: list, \n",
    "                           y_true_name: str, \n",
    "                           y_score_name: str,\n",
    "                           group_id_name: str) -> str:\n",
    "    import pandas as pd\n",
    "    from rexmex import RatingMetricSet, ScoreCard\n",
    "    \n",
    "    metric_set = RatingMetricSet()\n",
    "    score_card = ScoreCard(metric_set)\n",
    "    \n",
    "    input_column_names = [y_true_name, y_score_name, group_id_name]\n",
    "    df = pd.DataFrame(input_data, columns = input_column_names)\n",
    "    df.rename(columns={y_true_name: 'y_true', y_score_name:'y_score'}, inplace=True)\n",
    "    \n",
    "    df = score_card.generate_report(df,grouping=[group_id_name]).reset_index()\n",
    "    df.drop('level_1', axis=1, inplace=True)\n",
    "    \n",
    "    return [df.values.tolist(), df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying the UDF to Snowflake makes it available for all users.  This is a regression evaluation.  Likely we will want to deploy a categorical function as well or add if/then logic to our single instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from citibike_ml.model_eval import eval_model_output_func\n",
    "#Deploy the model eval UDF\n",
    "\n",
    "dep = 'rexmex.zip'\n",
    "source_dir = './dependencies/'\n",
    "\n",
    "session.clearImports()\n",
    "session.addImport(source_dir+dep)\n",
    "session.addImport('citibike_ml')\n",
    "\n",
    "model_stage_name = str(project_db_schema)+'.'+'model_stage'\n",
    "_ = session.sql('CREATE STAGE IF NOT EXISTS model_stage').collect()\n",
    "\n",
    "eval_model_output_udf = session.udf.register(eval_model_output_func, \n",
    "                                              name=\"eval_model_output_udf\",\n",
    "                                              is_permanent=True,\n",
    "                                              stage_location='@'+str(model_stage_name), \n",
    "                                              replace=True)\n",
    "\n",
    "eval_model_output_udf.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model eval output\n",
    "\n",
    "eval_df = session.table(pred_table_name)\\\n",
    "                 .select(F.array_agg(F.array_construct('COUNT', 'PRED', 'STATION_ID')).alias('input_data'))\n",
    "\n",
    "output_df = eval_df.select(F.call_udf('eval_model_output_udf',\n",
    "                                      'INPUT_DATA',\n",
    "                                      F.lit('COUNT'), \n",
    "                                      F.lit('PRED'),\n",
    "                                      F.lit('STATION_ID'))).collect()\n",
    "\n",
    "df = pd.DataFrame(data = ast.literal_eval(output_df[0][0])[0], \n",
    "                      columns = ast.literal_eval(output_df[0][0])[1])\n",
    "\n",
    "eval_df = session.createDataFrame(df).write.saveAsTable(eval_table_name)\n",
    "\n",
    "df = session.table(eval_table_name).toPandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate all functions for orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile citibike_ml/model_eval.py\n",
    "\n",
    "def eval_model_output_func(input_data: list, \n",
    "                           y_true_name: str, \n",
    "                           y_score_name: str,\n",
    "                           group_id_name: str) -> str:\n",
    "    import pandas as pd\n",
    "    from rexmex import RatingMetricSet, ScoreCard\n",
    "    \n",
    "    metric_set = RatingMetricSet()\n",
    "    score_card = ScoreCard(metric_set)\n",
    "    \n",
    "    input_column_names = [y_true_name, y_score_name, group_id_name]\n",
    "    df = pd.DataFrame(input_data, columns = input_column_names)\n",
    "    df.rename(columns={y_true_name: 'y_true', y_score_name:'y_score'}, inplace=True)\n",
    "    \n",
    "    df = score_card.generate_report(df,grouping=[group_id_name]).reset_index()\n",
    "    df.drop('level_1', axis=1, inplace=True)\n",
    "    \n",
    "    return [df.values.tolist(), df.columns.tolist()]\n",
    "\n",
    "def deploy_eval_udf(session, function_name, model_stage_name) -> str:\n",
    "    from citibike_ml.model_eval import eval_model_output_func\n",
    "\n",
    "    dep = 'rexmex.zip'\n",
    "    source_dir = './dependencies/'\n",
    "\n",
    "    session.clearImports()\n",
    "    session.addImport(source_dir+dep)\n",
    "    session.addImport('citibike_ml')\n",
    "\n",
    "    eval_model_output_udf = session.udf.register(eval_model_output_func, \n",
    "                                                  name=function_name,\n",
    "                                                  is_permanent=True,\n",
    "                                                  stage_location='@'+str(model_stage_name), \n",
    "                                                  replace=True)\n",
    "\n",
    "    return eval_model_output_udf.name\n",
    "\n",
    "def evaluate_station_predictions(session, pred_table_name, eval_model_udf_name, eval_table_name) -> str:\n",
    "    from snowflake.snowpark import functions as F\n",
    "    import pandas as pd\n",
    "    import ast\n",
    "    \n",
    "    eval_df = session.table(pred_table_name)\\\n",
    "                     .select(F.array_agg(F.array_construct('COUNT', 'PRED', 'STATION_ID')).alias('input_data'))\n",
    "\n",
    "    output_df = eval_df.select(F.call_udf(eval_model_udf_name,\n",
    "                                          'INPUT_DATA',\n",
    "                                          F.lit('COUNT'), \n",
    "                                          F.lit('PRED'),\n",
    "                                          F.lit('STATION_ID'))).collect()\n",
    "    \n",
    "    df = pd.DataFrame(data = ast.literal_eval(output_df[0][0])[0], \n",
    "                      columns = ast.literal_eval(output_df[0][0])[1])\n",
    "\n",
    "    eval_df = session.createDataFrame(df).write.saveAsTable(eval_table_name)\n",
    "\n",
    "\n",
    "    return eval_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize: eval_df = eval_df.groupBy('STATION_ID')\\\n",
    "#                  .agg(F.array_agg(F.array_construct(F.col('COUNT'), F.col('PRED'))).alias('INPUT_DATA'))\\\n",
    "#                  #.filter(F.col('STATION_ID') == F.lit('426'))"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "cforbe"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "msauthor": "trbye"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
